# LLM Gateway (OpenAI-style API key front door)

ä¸€ä¸ªè½»é‡ Node.js ç½‘å…³ï¼Œç”¨ `Authorization: Bearer sk-xxx` éªŒè¯ API Keyï¼Œå†æŠŠè¯·æ±‚è½¬å‘åˆ°ä½ æœ¬æœºçš„ `llama-server` (`localhost:5857`)ã€‚å¯ç”¨äº Cloudflare Tunnel å…¬å¼€è®¿é—®ã€‚

## åˆå§‹åŒ–

```bash
cd gateway
npm install
cp .env.example .env
# æŒ‰éœ€ç¼–è¾‘ .env ä¸­çš„ LLM_API_KEYSã€LLM_UPSTREAMã€GATEWAY_PORT
```

`.env` ç¤ºä¾‹ï¼š
```
LLM_API_KEYS=sk-tno-llm-2025-1,sk-tno-llm-2025-2
LLM_UPSTREAM=http://127.0.0.1:5857
GATEWAY_PORT=8787
# å¯é€‰ï¼šé™åˆ¶å‰ç«¯æ¥æº
# CORS_ALLOW_ORIGIN=http://localhost:7788
```

## å¯åŠ¨é¡ºåº
1) å…ˆå¯åŠ¨ `llama-server`ï¼ˆä¾‹å¦‚ç«¯å£ 5857ï¼‰ã€‚  
2) å†å¯åŠ¨ç½‘å…³ï¼š
```bash
npm start
# æˆ– node gateway.js
```
çœ‹åˆ°æ—¥å¿—ï¼š
```
âœ… LLM Gateway starting with config:
  - Port: 8787
  - Upstream: http://127.0.0.1:5857
  - Valid API keys: 2
ğŸš€ LLM API Gateway listening on http://localhost:8787
```

### ç”¨ PM2 ä¸€é”®å¯åŠ¨ï¼ˆæ¨èï¼‰
åœ¨é¡¹ç›®æ ¹ç›®å½•æœ‰ç®€åŒ–çš„ PM2 èœå• `pm2-simple.js`ï¼Œå¯åŒæ—¶ç®¡ç† llama/gateway/tunnelã€‚æ‰€æœ‰å‘½ä»¤å¯åœ¨ `pm2-config.json` ä¸­é›†ä¸­ä¿®æ”¹ï¼ˆæ¨¡å‹è·¯å¾„ã€tunnel åç§°ã€config.yml è·¯å¾„ã€å·¥ä½œç›®å½•ç­‰ï¼‰ï¼š
```bash
node pm2-simple.js
```
å¸¸ç”¨æŒ‰é”®ï¼š
- `a` / `7`ï¼šå¯åŠ¨å…¨éƒ¨ï¼ˆllama + gateway + tunnelï¼ŒæŒ‰éœ€ç¼–è¾‘å‘½ä»¤ï¼‰
- `k` / `8`ï¼šåœæ­¢å…¨éƒ¨
- `0`ï¼šåˆ·æ–°çŠ¶æ€è¡¨
- `9`ï¼šæŸ¥çœ‹ gateway æ—¥å¿—ï¼ˆæ’æŸ¥é”™è¯¯ï¼‰
å¦‚éœ€ä¿®æ”¹ llama æ¨¡å‹æˆ–ç«¯å£ï¼Œç¼–è¾‘ `pm2-simple.js` é¡¶éƒ¨çš„ `llama` é¢„è®¾ï¼›ç¡®ä¿ç«¯å£ä¸ `.env` çš„ `LLM_UPSTREAM` ä¸€è‡´ã€‚
é»˜è®¤ tunnel é…ç½®ä¼šè¯»å– `./cloudflared-config.yml`ï¼ˆä½äºä»“åº“æ ¹ç›®å½•ï¼‰ï¼›è‹¥æ–‡ä»¶ä¸å­˜åœ¨ä¸”è·¯å¾„åœ¨ä»“åº“å†…ï¼Œè¿è¡Œ `pm2-simple.js` ä¼šè‡ªåŠ¨ç”Ÿæˆæ¨¡æ¿ï¼Œè¯·å…ˆå¡«å¥½ tunnel åç§°ã€å‡­è¯æ–‡ä»¶è·¯å¾„å’Œ ingress åŸŸååå†å¯åŠ¨ã€‚

## æœ¬åœ°æµ‹è¯•
æ­£ç¡®çš„ Keyï¼š
```bash
curl http://localhost:8787/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-tno-llm-2025-1" \
  -d '{
    "model": "gpt-oss-20b",
    "messages": [{ "role": "user", "content": "Hello via gateway" }]
  }'
```
é”™è¯¯æˆ–ç¼ºå¤±çš„ Key ä¼šè¿”å›ï¼š
```json
{
  "error": {
    "message": "Incorrect API key provided.",
    "type": "invalid_api_key"
  }
}
```

## Cloudflare Tunnel é…ç½®ç¤ºä¾‹
æŠŠ Tunnel çš„ `service` æŒ‡å‘ç½‘å…³ç«¯å£ï¼ˆ8787ï¼‰ï¼Œè€Œä¸æ˜¯ç›´æ¥æŒ‡å‘ llama-serverï¼š
```yaml
ingress:
  - hostname: api.b1122333.com
    service: http://localhost:8787
  - service: http_status:404
```
é‡å¯ Tunnel åï¼Œå…¬ç½‘è°ƒç”¨ï¼š
```bash
curl https://api.b1122333.com/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer sk-tno-llm-2025-1" \
  -d '{
    "model": "gpt-oss-20b",
    "messages": [{ "role": "user", "content": "Hello from Internet via Gateway" }]
  }'
```

## å‰ç«¯å¦‚ä½•è°ƒç”¨
- `Base URL` è®¾ç½®ä¸ºæŒ‡å‘ç½‘å…³ï¼ˆä¾‹å¦‚ `https://api.b1122333.com/v1`ï¼‰ã€‚
- `Authorization` å¤´ç”¨ `Bearer sk-...`ã€‚
- å¦‚æœä½ ç»§ç»­ä¿ç•™ Cloudflare çš„ `X-My-LLM-Key` WAF è§„åˆ™ï¼Œå¯ä»¥åœ¨å‰ç«¯é¢å¤–æ·»åŠ è¯¥ Headerï¼›å¦åˆ™åªç”¨ Bearer å³å¯ã€‚

## åç»­æ‰©å±•æ€è·¯
- æŠŠ API Keys æ”¾æ•°æ®åº“ï¼Œåšå¼€å…³ã€å¤‡æ³¨ã€é€Ÿç‡é™åˆ¶ã€‚
- å¢åŠ  `/v1/embeddings` ç­‰è½¬å‘è·¯ç”±ã€‚
- è¯·æ±‚æ—¥å¿—å†™å…¥æ–‡ä»¶æˆ–å¯¹è±¡å­˜å‚¨ï¼Œæ–¹ä¾¿å®¡è®¡/è®¡è´¹ã€‚
